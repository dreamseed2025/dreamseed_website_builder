<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DreamSeed - Direct Web Voice Call</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 40px 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: white;
        }
        
        .container {
            background: rgba(255, 255, 255, 0.1);
            padding: 40px;
            border-radius: 20px;
            backdrop-filter: blur(10px);
            text-align: center;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
        }
        
        .call-interface {
            background: rgba(255, 255, 255, 0.1);
            padding: 40px;
            border-radius: 20px;
            margin: 30px 0;
            border: 2px solid rgba(255, 255, 255, 0.2);
        }
        
        .control-btn {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            font-size: 2.5em;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 8px 25px rgba(0,0,0,0.3);
            background: linear-gradient(45deg, #27ae60, #2ecc71);
            color: white;
            margin: 20px;
        }
        
        .control-btn:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 35px rgba(39, 174, 96, 0.4);
        }
        
        .control-btn:disabled {
            background: rgba(255, 255, 255, 0.3);
            cursor: not-allowed;
            transform: none;
        }
        
        .audio-controls {
            margin: 20px 0;
            display: none;
        }
        
        .mic-indicator {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            background: linear-gradient(45deg, #f39c12, #e67e22);
            color: white;
            border: none;
            font-size: 2em;
            cursor: pointer;
            margin: 15px;
            transition: all 0.3s ease;
            box-shadow: 0 8px 25px rgba(0,0,0,0.3);
            z-index: 10;
            position: relative;
        }
        
        .mic-indicator.active {
            background: linear-gradient(45deg, #27ae60, #2ecc71);
            animation: pulse 1s infinite;
        }
        
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }
        
        .debug-panel {
            background: rgba(0, 0, 0, 0.4);
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            text-align: left;
            max-height: 300px;
            overflow-y: auto;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ DreamSeed Direct Web Call</h1>
        <p>Browser-based voice recording with VAPI assistant</p>
        
        <div class="call-interface">
            <div id="start-interface">
                <button id="start-call-btn" class="control-btn" onclick="requestMicPermission()">
                    üìû
                </button>
                <p>Click to start voice consultation</p>
            </div>
            
            <div id="recording-interface" style="display: none;">
                <div class="audio-controls">
                    <button id="record-btn" class="mic-indicator">üé§</button>
                    <button id="hangup-btn" class="mic-indicator" style="background: linear-gradient(45deg, #e74c3c, #c0392b); font-size: 1.8em;">‚ùå</button>
                </div>
                <p id="recording-status">Ready to record</p>
                <p style="font-size: 0.9em; opacity: 0.8;">üé§ Record your question | ‚ùå End session</p>
                <audio id="audio-playback" controls style="width: 100%; margin: 20px 0; display: none;"></audio>
            </div>
        </div>
        
        <div class="debug-panel">
            <div style="color: #ffd700; font-weight: bold; margin-bottom: 10px;">Session Status:</div>
            <div id="debug-output">Ready to start...</div>
        </div>
        
        <div style="margin-top: 30px; font-size: 0.9em; opacity: 0.8;">
            <p><strong>How it works:</strong></p>
            <p>1. Click to request microphone access</p>
            <p>2. Record your question</p>
            <p>3. AI processes and responds with voice</p>
        </div>
    </div>

    <script>
        let mediaRecorder = null;
        let audioChunks = [];
        let isRecording = false;
        let config = null;
        let mediaStream = null;
        
        function log(message, type = 'info') {
            const timestamp = new Date().toLocaleTimeString();
            const debugOutput = document.getElementById('debug-output');
            const entry = document.createElement('div');
            entry.style.color = type === 'error' ? '#e74c3c' : type === 'success' ? '#27ae60' : '#ffffff';
            entry.textContent = `[${timestamp}] ${message}`;
            debugOutput.appendChild(entry);
            debugOutput.scrollTop = debugOutput.scrollHeight;
            console.log(message);
        }
        
        // Load VAPI configuration
        async function loadConfig() {
            try {
                const response = await fetch('/api/vapi-config');
                if (!response.ok) throw new Error(`HTTP ${response.status}`);
                config = await response.json();
                log(`‚úÖ Config loaded`, 'success');
                return true;
            } catch (error) {
                log(`‚ùå Config failed: ${error.message}`, 'error');
                return false;
            }
        }
        
        // Request microphone permission
        async function requestMicPermission() {
            try {
                log('Requesting microphone access...');
                mediaStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 44100
                    } 
                });
                
                log('‚úÖ Microphone access granted', 'success');
                
                // Setup media recorder
                mediaRecorder = new MediaRecorder(mediaStream, {
                    mimeType: 'audio/webm;codecs=opus'
                });
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };
                
                mediaRecorder.onstop = async () => {
                    log('Processing audio...');
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    audioChunks = [];
                    
                    // Show audio playback
                    const audioURL = URL.createObjectURL(audioBlob);
                    const audioElement = document.getElementById('audio-playback');
                    audioElement.src = audioURL;
                    audioElement.style.display = 'block';
                    
                    // Send to speech-to-text and AI processing
                    await processAudio(audioBlob);
                };
                
                // Load config
                await loadConfig();
                
                // Show recording interface
                document.getElementById('start-interface').style.display = 'none';
                document.getElementById('recording-interface').style.display = 'block';
                
                // Attach event listeners to buttons
                document.getElementById('record-btn').addEventListener('click', toggleRecording);
                document.getElementById('hangup-btn').addEventListener('click', endSession);
                
                log('‚úÖ Ready to record!', 'success');
                log('‚úÖ Button event listeners attached', 'success');
                document.getElementById('recording-status').textContent = 'Press microphone to start recording';
                
            } catch (error) {
                log(`‚ùå Microphone access failed: ${error.message}`, 'error');
            }
        }
        
        // Toggle recording
        function toggleRecording() {
            log('üî¥ Toggle recording clicked!');
            const recordBtn = document.getElementById('record-btn');
            const status = document.getElementById('recording-status');
            
            if (!mediaRecorder) {
                log('‚ùå Media recorder not available', 'error');
                return;
            }
            
            if (!isRecording) {
                // Start recording
                audioChunks = [];
                mediaRecorder.start();
                isRecording = true;
                
                recordBtn.classList.add('active');
                recordBtn.textContent = 'üî¥';
                status.textContent = 'Recording... Press again to stop';
                log('üé§ Recording started');
                
            } else {
                // Stop recording
                mediaRecorder.stop();
                isRecording = false;
                
                recordBtn.classList.remove('active');
                recordBtn.textContent = 'üé§';
                status.textContent = 'Processing your recording...';
                log('üîá Recording stopped');
            }
        }
        
        // Process audio with AI
        async function processAudio(audioBlob) {
            try {
                log('Simulating AI processing...');
                
                // In a real implementation, you would:
                // 1. Convert audio to text (speech-to-text API)
                // 2. Send text to VAPI assistant
                // 3. Get response and convert to audio (text-to-speech)
                
                // For now, simulate the process
                document.getElementById('recording-status').textContent = 'AI is thinking...';
                
                // Simulate processing delay
                await new Promise(resolve => setTimeout(resolve, 2000));
                
                // Simulate AI response
                log('‚úÖ AI processing complete', 'success');
                document.getElementById('recording-status').textContent = 'AI: "Thank you for your question about LLC formation. Based on what I heard, I\'d recommend starting with our Basic plan. Would you like me to explain the formation process?"';
                
                // Reset for next recording
                setTimeout(() => {
                    document.getElementById('recording-status').textContent = 'Ready for your next question';
                    document.getElementById('audio-playback').style.display = 'none';
                }, 5000);
                
            } catch (error) {
                log(`‚ùå AI processing failed: ${error.message}`, 'error');
                document.getElementById('recording-status').textContent = 'Processing failed. Try again.';
            }
        }
        
        // End session  
        function endSession() {
            log('üî¥ End session clicked!');
            log('Ending session...');
            
            // Stop any active recording
            if (isRecording && mediaRecorder) {
                mediaRecorder.stop();
                isRecording = false;
            }
            
            // Stop all media tracks
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => {
                    track.stop();
                    log('Stopped media track');
                });
                mediaStream = null;
            }
            
            // Reset interface
            document.getElementById('start-interface').style.display = 'block';
            document.getElementById('recording-interface').style.display = 'none';
            document.getElementById('audio-playback').style.display = 'none';
            
            // Reset button states
            const recordBtn = document.getElementById('record-btn');
            recordBtn.classList.remove('active');
            recordBtn.textContent = 'üé§';
            
            isRecording = false;
            mediaRecorder = null;
            log('‚úÖ Session ended - all tracks stopped', 'success');
        }
        
        // Initialize
        window.addEventListener('DOMContentLoaded', () => {
            log('Direct web call interface ready');
            
            // Check if browser supports required features
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                log('‚ùå Browser does not support media recording', 'error');
                document.getElementById('start-call-btn').disabled = true;
            }
        });
    </script>
</body>
</html>